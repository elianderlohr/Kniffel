{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-03T09:42:35.703556Z",
     "iopub.status.busy": "2022-08-03T09:42:35.702457Z",
     "iopub.status.idle": "2022-08-03T09:42:54.664335Z",
     "shell.execute_reply": "2022-08-03T09:42:54.662957Z",
     "shell.execute_reply.started": "2022-08-03T09:42:35.703472Z"
    },
    "id": "b_ezGGzkUkfi",
    "outputId": "40b3577e-018e-4753-bc33-7642ceae0587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-rl in /usr/local/lib/python3.9/dist-packages (0.4.2)\n",
      "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.9/dist-packages (from keras-rl) (2.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: keras-rl2 in /usr/local/lib/python3.9/dist-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.9.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.7.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.23.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (63.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.26.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.9.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.47.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (14.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.35.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (2.9.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->tensorflow->keras-rl2) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-rl2) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (4.12.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.7)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.23.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.8.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.9/dist-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.9/dist-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.23.1)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.9/dist-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic->optuna) (1.2.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from cliff->optuna) (5.9.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.9/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.9/dist-packages (from cmd2>=1.0.0->cliff->optuna) (18.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic->optuna) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras-rl\n",
    "!pip install keras-rl2\n",
    "!pip install gym\n",
    "!pip install sympy\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T09:56:38.797260Z",
     "iopub.status.busy": "2022-08-03T09:56:38.796885Z",
     "iopub.status.idle": "2022-08-03T09:56:42.904390Z",
     "shell.execute_reply": "2022-08-03T09:56:42.903101Z",
     "shell.execute_reply.started": "2022-08-03T09:56:38.797229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:2 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]            \n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]                \n",
      "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB] \n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2044 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.6 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [885 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1411 kB]\n",
      "Get:9 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [774 B]   \n",
      "Get:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [26.6 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]       \n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1174 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2498 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1525 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.5 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Fetched 23.2 MB in 2s (9941 kB/s)                            \n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T09:57:46.075816Z",
     "iopub.status.busy": "2022-08-03T09:57:46.075437Z",
     "iopub.status.idle": "2022-08-03T09:57:50.864297Z",
     "shell.execute_reply": "2022-08-03T09:57:50.863092Z",
     "shell.execute_reply.started": "2022-08-03T09:57:46.075798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "default-libmysqlclient-dev is already the newest version (1.0.5ubuntu2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libmysqlclient-dev is already the newest version (8.0.30-0ubuntu0.20.04.2).\n",
      "libmysqlclient-dev set to manually installed.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y default-libmysqlclient-dev\n",
    "!sudo apt-get install libmysqlclient-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T09:58:13.637403Z",
     "iopub.status.busy": "2022-08-03T09:58:13.633969Z",
     "iopub.status.idle": "2022-08-03T09:58:23.550005Z",
     "shell.execute_reply": "2022-08-03T09:58:23.548907Z",
     "shell.execute_reply.started": "2022-08-03T09:58:13.637368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.9/dist-packages (8.0.30)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.11.0 in /usr/local/lib/python3.9/dist-packages (from mysql-connector-python) (3.19.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mysqlclient\n",
      "  Using cached mysqlclient-2.1.1.tar.gz (88 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: mysqlclient\n",
      "  Building wheel for mysqlclient (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp39-cp39-linux_x86_64.whl size=107573 sha256=d16d504571fe421026efeddaca66df2e67bc46b5b377c3bd0fddcc8579603b03\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/a5/27/c6312d8008951cfd5511684378a9e057b82006c70e1fea6107\n",
      "Successfully built mysqlclient\n",
      "Installing collected packages: mysqlclient\n",
      "Successfully installed mysqlclient-2.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install mysqlclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T09:59:28.907210Z",
     "iopub.status.busy": "2022-08-03T09:59:28.906835Z",
     "iopub.status.idle": "2022-08-03T09:59:28.913363Z",
     "shell.execute_reply": "2022-08-03T09:59:28.912688Z",
     "shell.execute_reply.started": "2022-08-03T09:59:28.907170Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "sys.path.append(str(\"/notebook/\"))\n",
    "\n",
    "import src.ai.ai_optuna as ai_optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T10:05:34.684996Z",
     "iopub.status.busy": "2022-08-03T10:05:34.684123Z",
     "iopub.status.idle": "2022-08-03T10:05:34.688808Z",
     "shell.execute_reply": "2022-08-03T10:05:34.687952Z",
     "shell.execute_reply.started": "2022-08-03T10:05:34.684967Z"
    }
   },
   "outputs": [],
   "source": [
    "create_new = \"true\"\n",
    "_pw = \"AVNS_SPq4Z0yR4wUrtxNJVVc\"\n",
    "study_name = \"kniffel_22_08_03_v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T10:05:45.057985Z",
     "iopub.status.busy": "2022-08-03T10:05:45.056927Z",
     "iopub.status.idle": "2022-08-03T10:05:45.067834Z",
     "shell.execute_reply": "2022-08-03T10:05:45.066426Z",
     "shell.execute_reply.started": "2022-08-03T10:05:45.057952Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_1(trial):\n",
    "    base_hp = {\n",
    "        \"windows_length\": [1],  # range(1, 3),\n",
    "        \"batch_size\": [32],\n",
    "        \"dqn_target_model_update\": [\n",
    "            0.00001,\n",
    "            0.0005,\n",
    "            0.0001,\n",
    "            0.0005,\n",
    "            0.001,\n",
    "            0.005,\n",
    "            0.01,\n",
    "            0.05,\n",
    "            0.1,\n",
    "            50,\n",
    "            100,\n",
    "            200,\n",
    "            300,\n",
    "            400,\n",
    "            500,\n",
    "            750,\n",
    "            1000,\n",
    "            2_500,\n",
    "            5_000,\n",
    "            7_500,\n",
    "            10_000,\n",
    "            15_000,\n",
    "        ],\n",
    "        \"dqn_dueling_option\": [\"avg\"],\n",
    "        \"activation\": [\"linear\", \"softmax\", \"sigmoid\"],\n",
    "        \"dqn_enable_double_dqn\": [True, False],\n",
    "        \"agent\": [\"DQN\", \"CEM\", \"SARSA\"],\n",
    "        \"linear_inner_policy\": [\n",
    "            \"EpsGreedyQPolicy\",\n",
    "        ],\n",
    "        \"train_policy\": [\n",
    "            \"LinearAnnealedPolicy\",\n",
    "            \"EpsGreedyQPolicy\",\n",
    "            \"GreedyQPolicy\",\n",
    "            \"BoltzmannQPolicy\",\n",
    "            \"MaxBoltzmannQPolicy\",\n",
    "            \"BoltzmannGumbelQPolicy\",\n",
    "        ],\n",
    "        \"test_policy\": [\n",
    "            \"LinearAnnealedPolicy\",\n",
    "            \"EpsGreedyQPolicy\",\n",
    "            \"GreedyQPolicy\",\n",
    "            \"BoltzmannQPolicy\",\n",
    "            \"MaxBoltzmannQPolicy\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    env_config = {\n",
    "        \"reward_step\": 0,\n",
    "        \"reward_roll_dice\": 0.5,\n",
    "        \"reward_game_over\": -200,\n",
    "        \"reward_slash\": -10,\n",
    "        \"reward_bonus\": 20,\n",
    "        \"reward_finish\": 50,\n",
    "    }\n",
    "\n",
    "    ai = KniffelAI(\n",
    "        load=False,\n",
    "        hyperparater_base=base_hp,\n",
    "        config_path=\"../../src/ai/Kniffel.CSV\",\n",
    "        path_prefix=\"\",\n",
    "        trial=trial,\n",
    "    )\n",
    "\n",
    "    score = ai.train(env_config=env_config, nb_steps=100_000)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T10:05:45.825213Z",
     "iopub.status.busy": "2022-08-03T10:05:45.824796Z",
     "iopub.status.idle": "2022-08-03T11:04:57.506629Z",
     "shell.execute_reply": "2022-08-03T11:04:57.403054Z",
     "shell.execute_reply.started": "2022-08-03T10:05:45.825186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-03 10:06:01,454]\u001b[0m A new study created in RDB with name: kniffel_22_08_03_v3\u001b[0m\n",
      "/usr/local/lib/python3.9/dist-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 144)               6048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 58)                8410      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,458\n",
      "Trainable params: 14,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/optuna/distributions.py:560: UserWarning: The distribution is specified by [1000, 1000000] and step=50000, but the range is not divisible by `step`. It will be replaced by [1000, 951000].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 48)                2016      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 58)                2842      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,210\n",
      "Trainable params: 7,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/optuna/distributions.py:560: UserWarning: The distribution is specified by [1000, 750000] and step=50000, but the range is not divisible by `step`. It will be replaced by [1000, 701000].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2688      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                6240      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 192)               18624     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                11194     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,746\n",
      "Trainable params: 38,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2056/50000 [>.............................] - ETA: 2:06 - reward: -48.2174Model: \"sequential\"\n",
      " 2074/50000 [>.............................] - ETA: 2:07 - reward: -48.2692_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 112)               4704      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 144)               16272     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 208)               30160     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                12122     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,258\n",
      "Trainable params: 63,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 4612/50000 [=>............................] - ETA: 2:04 - reward: -49.2867Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 144)               6048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 58)                986       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,354\n",
      "Trainable params: 9,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 6592/50000 [==>...........................] - ETA: 1:59 - reward: -49.4442Model: \"sequential\"\n",
      " 6603/50000 [==>...........................] - ETA: 1:59 - reward: -49.4503_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 144)               6048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 208)               30160     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                13376     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                3770      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,354\n",
      "Trainable params: 53,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "14465/50000 [=======>......................] - ETA: 1:37 - reward: -49.2339Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 176)               7392      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                16992     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 176)               17072     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                2832      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 58)                986       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,274\n",
      "Trainable params: 45,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "21774/50000 [============>.................] - ETA: 1:16 - reward: -48.8400Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                4032      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                7760      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 112)               9072      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 160)               18080     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 58)                9338      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,282\n",
      "21784/50000 [============>.................] - ETA: 1:16 - reward: -48.8347Trainable params: 48,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "26621/50000 [==============>...............] - ETA: 1:03 - reward: -49.1148Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                4032      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                7760      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 112)               9072      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 58)                6554      \n",
      "                                                                 \n",
      "=================================================================\n",
      "26631/50000 [==============>...............] - ETA: 1:03 - reward: -49.1105Total params: 33,898\n",
      "Trainable params: 33,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "27329/50000 [===============>..............] - ETA: 1:01 - reward: -49.1863Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               8064      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 48)                9264      \n",
      "27339/50000 [===============>..............] - ETA: 1:01 - reward: -49.1821                                                                 \n",
      " dense_2 (Dense)             (None, 58)                2842      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,170\n",
      "Trainable params: 20,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "30566/50000 [=================>............] - ETA: 52s - reward: -49.3363Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "30580/50000 [=================>............] - ETA: 52s - reward: -49.3261 Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 176)               7392      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 112)               19824     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 240)               27120     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 240)               57840     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 58)                13978     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,154\n",
      "Trainable params: 126,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37893/50000 [=====================>........] - ETA: 32s - reward: -49.2250Model: \"sequential\"\n",
      "37906/50000 [=====================>........] - ETA: 32s - reward: -49.2229_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 41)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                672       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 208)               3536      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                6688      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                1914      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,810\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "44105/50000 [=========================>....] - ETA: 21s - reward: -49.2058Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "50000/50000 [==============================] - 184s 4ms/step - reward: -49.1422\n",
      "12661 episodes - episode_reward: -194.069 [-222.968, -120.708] - mean_best_reward: 0.000\n",
      "\n",
      "Interval 2 (50000 steps performed)\n",
      " 3528/50000 [=>............................] - ETA: 3:22 - reward: -48.7922Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 5933/50000 [==>...........................] - ETA: 4:07 - reward: -49.00Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 9708/50000 [====>.........................] - ETA: 5:41 - reward: -49.0960Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 1015/50000 [..............................] - ETA: 12:26 - reward: -60.2157Training for 100000 steps ...\n",
      "15553/50000 [========>.....................] - ETA: 4:32 - reward: -48.7873Interval 1 (0 steps performed)\n",
      "15831/50000 [========>.....................] - ETA: 4:41 - reward: -48.79266 2508/50000 [>.......................15810/50000 [==Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  714/50000 [..............................] - ETA: 12:20 - reward: -46.1540Training for 100000 steps ...\n",
      " 1185/50000 [..............................] - ETA: 18:09 - reward: -61.2106Interval 1 (0 steps performed)\n",
      "  312/50000 [..............................] - ETA: 19:12 - reward: -76.2077  304/50000 [..............................] - ETA: 19:04 -Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  639/50000 [..............................] - ETA: 21:13 - reward: -72.4885Training for 100000 steps ...\n",
      "  327/50000 [..............................] - ETA: 22:24 - reward: -58.1451Interval 1 (0 steps performed)\n",
      " 1096/50000 [..............................] - ETA: 21:59 - reward: -46.8770Training for 100000 steps ...\n",
      "  702/50000 [..............................] - ETA: 21:46 - reward: -73.2974Interval 1 (0 steps performed)\n",
      "  992/50000 [..............................] - ETA: 23:17 - reward: -72.2502Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "50000/50000 [==============================] - 1930s 39ms/step - reward: -49.2078\n",
      "11684/50000 [======>.......................] - ETA: 1:36:34 - reward: -49.138312693 episodes - episode_reward: -193.839 [-221.613, -112.702] - mean_best_reward: 0.047\n",
      "\n",
      "Interval 2 (50000 steps performed)\n",
      "50000/50000 [==============================] - 2053s 41ms/step - reward: -48.5387\n",
      "15368/50000 [========>.....................] - ETA: 1:12:17 - reward: -60.8191done, took 2236.767 seconds\n",
      " 2226/50000 [>.............................] - ETA: 53:10 - reward: -48.7902Testing for 100 episodes ...\n",
      "15350/50000 [========>.....................] - ETA: 1:12:51 - reward: -76.7861Episode 1: reward: -198.708, steps: 2\n",
      "16085/50000 [========>.....................] - ETA: 1:08:42 - reward: -48.6368Episode 2: reward: -197.214, steps: 2\n",
      "16126/50000 [========>.....................] - ETA: 1:09:00 - reward: -76.9781Episode 3: reward: -198.708, steps: 2\n",
      "16086/50000 [========>.....................] - ETA: 1:08:42 - reward: -48.6337Episode 4: reward: -198.121, steps: 2\n",
      "15352/50000 [========>.....................] - ETA: 1:12:51 - reward: -76.7888Episode 5: reward: -198.708, steps: 2\n",
      " 2233/50000 [>.............................] - ETA: 53:08 - reward: -48.8119Episode 6: reward: -198.708, steps: 2\n",
      "15353/50000 [========>.....................] - ETA: 1:12:51 - reward: -76.7968isode 7: reward: -198.708, steps:\n",
      "18288/50000 [=========>....................] - ETA: 58:23 - reward: -38.3549Episode 8: reward: -198.121, steps: 2\n",
      "16088/50000 [========>.....................] - ETA: 1:08:42 - reward: -48.6399Episode 9: reward: -208.974, steps: 2\n",
      " 2237/50000 [>.............................] - ETA: 53:06 - reward: -48.7193Episode 10: reward: -198.121, steps: 2\n",
      "15354/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.8048Episode 11: reward: -198.708, steps: 2\n",
      "16089/50000 [========>.....................] - ETA: 1:08:42 - reward: -48.6368Episode 12: reward: -198.708, steps: 2\n",
      "16129/50000 [========>.....................] - ETA: 1:09:00 - reward: -76.9884Episode 13: reward: -208.974, steps: 2\n",
      "12423/50000 [======>.......................] - ETA: 1:36:36 - reward: -48.97Episode 14: reward: -208.974, steps: 2\n",
      "16130/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9960Episode 15: reward: -208.974, steps: 2\n",
      "18290/50000 [=========>....................] - ETA: 58:23 - reward: -38.3615Episode 16: reward: -197.214, steps: 2\n",
      "15575/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3341Episode 17: reward: -198.708, step\n",
      "16131/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.99Episode 18: reward: -208.974, steps: 2\n",
      "15357/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.8026Episode 19: reward: -198.121, steps: 2\n",
      "14640/50000 [=======>......................] - ETA: 1:22:04 - reward: -41.79Episode 20: reward: -198.121, steps: 2\n",
      " 2248/50000 [>.............................] - ETA: 53:03 - reward: -48.6450Episode 21: reward: -198.708, steps: 2\n",
      " 2249/50000 [>.............................] - ETA: 53:03 - reward: -48.6227Episode 22: reward: -208.974, steps: 2\n",
      "15578/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3342Episode 23: reward: -198.121, steps: 2\n",
      "18293/50000 [=========>....................] - ETA: 58:23 - reward: -38.3550Episode 24: reward: -208.974, steps: 2\n",
      "15799/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3706Episode 25: reward: -198.708, steps: 2\n",
      "16094/50000 [========>.....................] - ETA: 1:08:41 - reward: -48.6334Episode 26: reward: -198.708, steps: 2\n",
      "11697/50000 [======>.......................] - ETA: 1:45:16 - reward: -71.6708Episode 27: reward: -198.708, steps: 2\n",
      " 2254/50000 [>.............................] - ETA: 53:05 - reward: -48.6896Episode 28: reward: -198.708, steps: 2\n",
      " 2255/50000 [>.............................] - ETA: 53:04 - reward: -48.6675Episode 29: reward: -198.708, steps: 2\n",
      "15801/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3773Episode 30: reward: -198.121, steps: 2\n",
      "15380/50000 [========>.....................] - ETA: 1:12:17 - reward: -60.8104Episode 31: reward: -198.708, steps: 2\n",
      "12428/50000 [======>.......................] - ETA: 1:36:37 - reward: -48.9903Episode 32: reward: -198.121, steps: 2\n",
      "15582/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3303Episode 33: reward: -198.708, steps:\n",
      "16137/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9870Episode 34: reward: -198.708, steps:\n",
      "15363/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.7982Episode 35: reward: -198.121, steps: 2\n",
      "15583/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3261Episode 36: reward: -198.708, steps: 2\n",
      "16099/50000 [========>.....................] - ETA: 1:08:41 - reward: -48.6303Episode 37: reward: -208.974, steps:\n",
      " 2263/50000 [>.............................] - ETA: 53:07 - reward: -48.6640Episode 38: reward: -198.708, steps: 2\n",
      "15364/50000 [========>.....................] - ETA: 1:12:51 - reward: -76.79Episode 39: reward: -208.974, steps: 2\n",
      "15805/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3657Episode 40: reward: -208.974, steps: 2\n",
      "15585/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3306Episode 41: reward: -198.708, steps: 2\n",
      "15806/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3754Episode 42: reward: -198.121, steps: 2\n",
      "15586/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3263Episode 43: reward: -198.121, steps: 2\n",
      "15807/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3724Episode 44: reward: -198.708, steps: 2\n",
      "16142/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9879Episode 45: reward: -198.708, steps: 2\n",
      "15587/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3350Episode 46: reward: -208.974, steps: 2\n",
      "14647/50000 [=======>......................] - ETA: 1:22:05 - reward: -41.8045Episode 47: reward: -198.121, steps: 2\n",
      "15387/50000 [========>.....................] - ETA: 1:12:17 - reward: -60.8096Episode 48: reward: -198.708, steps: 2\n",
      "15809/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3668Episode 49: reward: -198.708, steps: 2\n",
      " 2274/50000 [>.............................] - ETA: 53:10 - reward: -48.6861Episode 50: reward: -198.708, steps: 2\n",
      "15589/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3266Episode 51: reward: -208.974, steps: 2\n",
      "18303/50000 [=========>....................] - ETA: 58:23 - reward: -38.3557Episode 52: reward: -208.974, steps: 2\n",
      "15370/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.8148Episode 53: reward: -208.974, steps: 2\n",
      "15371/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.8227Episode 54: reward: -198.708, steps: 2\n",
      "11704/50000 [======>.......................] - ETA: 1:45:18 - reward: -71.6615Episode 55: reward: -198.708, steps: 2\n",
      " 2279/50000 [>.............................] - ETA: 53:11 - reward: -48.7525Episode 56: reward: -208.974, steps: 2\n",
      "15372/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.8177Episode 57: reward: -198.708, steps: 2\n",
      " 2281/50000 [>.............................] - ETA: 53:10 - reward: -48.7078Episode 58: reward: -208.974, steps: 2\n",
      "14651/50000 [=======>......................] - ETA: 1:22:05 - reward: -41.8062Episode 59: reward: -208.974, steps: 2\n",
      "16107/50000 [========>.....................] - ETA: 1:08:42 - reward: -48.6561Episode 60: reward: -208.974, steps: 2\n",
      "12437/50000 [======>.......................] - ETA: 1:36:37 - reward: -48.9860Episode 61: reward: -198.708, steps: 2\n",
      "12438/50000 [======>.......................] - ETA: 1:36:37 - reward: -48.9820Episode 62: reward: -198.121, steps: 2\n",
      "16150/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9988Episode 63: reward: -198.708, steps: 2\n",
      "15375/50000 [========>.....................] - ETA: 1:12:50 - reward: -76.8155Episode 64: reward: -198.121, steps: 2\n",
      "16151/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9946Episode 65: reward: -198.121, steps: 2\n",
      "Episode 66: reward: -208.974, steps: 2\n",
      "11708/50000 [======>.......................] - ETA: 1:45:18 - reward: -71.6537Episode 67: reward: -208.974, steps: 2\n",
      "14655/50000 [=======>......................] - ETA: 1:22:05 - reward: -41.8077Episode 68: reward: -198.708, steps: 2\n",
      "15596/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3358Episode 69: reward: -198.708, steps: 2\n",
      "18311/50000 [=========>....................] - ETA: 58:23 - reward: -38.3497Episode 70: reward: -198.708, steps:\n",
      "16112/50000 [========>.....................] - ETA: 1:08:41 - reward: -48.67Episode 71: reward: -208.974, steps: 2\n",
      "15819/50000 [========>.....................] - ETA: 1:10:19 - reward: -46.3616Episode 72: reward: -198.708, steps: 2\n",
      "14656/50000 [=======>......................] - ETA: 1:22:05 - reward: -41.80Episode 73: reward: -208.974, steps: 2\n",
      " 2296/50000 [>.............................] - ETA: 53:11 - reward: -48.7246Episode 74: reward: -198.708, steps: 2\n",
      "16114/50000 [========>.....................] - ETA: 1:08:41 - reward: -48.6841Episode 75: reward: -198.121, steps:\n",
      " 2298/50000 [>.............................] - ETA: 53:11 - reward: -48.6810Episode 76: reward: -208.974, steps: 2\n",
      "15397/50000 [========>.....................] - ETA: 1:12:17 - reward: -60.8214Episode 77: reward: -208.974, steps: 2\n",
      "12443/50000 [======>.......................] - ETA: 1:36:37 - reward: -48.9786Episode 78: reward: -208.974, steps: 2\n",
      "16157/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9904Episode 79: reward: -198.708, steps: 2\n",
      "15601/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.32Episode 80: reward: -198.708, steps: 2\n",
      " 2310/50000 [>.............................] - ETA: 53:03 - reward: -48.502969444/50000 [======>.......................] - ETA: 1:36:37 - reward: -48.Episode 81: reward: -198.121, step\n",
      "15602/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3363Episode 82: reward: -198.121, steps: 2\n",
      "16118/50000 [========>.....................] - ETA: 1:08:41 - reward: -48.6847Episode 83: reward: -208.974, steps: 2\n",
      "16159/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.9932Episode 84: reward: -208.974, steps: 2\n",
      "14661/50000 [=======>......................] - ETA: 1:22:05 - reward: -41.8169Episode 85: reward: -208.974, steps: 2\n",
      "16160/50000 [========>.....................] - ETA: 1:08:59 - reward: -76.98Episode 86: reward: -208.974, steps: 2\n",
      "11716/50000 [======>.......................] - ETA: 1:45:17 - reward: -71.6552Episode 87: reward: -208.974, steps: 2\n",
      "12446/50000 [======>.......................] - ETA: 1:36:38 - reward: -48.9826Episode 88: reward: -208.974, steps: 2\n",
      " 2315/50000 [>.............................] - ETA: 53:06 - reward: -48.5686Episode 89: reward: -208.974, steps: 2\n",
      " 2317/50000 [>.............................] - ETA: 53:04 - reward: -48.5255Episode 90: reward: -208.974, steps: 2\n",
      "16162/50000 [========>.....................] - ETA: 1:08:58 - reward: -76.9909Episode 91: reward: -198.121, steps: 2\n",
      "15829/50000 [========>.....................] - ETA: 1:10:18 - reward: -46.3570Episode 92: reward: -198.121, steps: 2\n",
      " 2321/50000 [>.............................] - ETA: 53:03 - reward: -48.52Episode 93: reward: -198.708, steps: 2\n",
      "14664/50000 [=======>......................] - ETA: 1:22:05 - reward: -41.8218Episode 94: reward: -198.708, steps: 2\n",
      " 2323/50000 [>.............................] - ETA: 53:02 - reward: -48.5676Episode 95: reward: -198.121, steps: 2\n",
      " 2324/50000 [>.............................] - ETA: 53:02 - reward: -48.546228Episode 96: reward: -208.974, steps:\n",
      "18323/50000 [=========>....................] - ETA: 58:22 - reward: -38.345408Episode 97: reward: -208.974, step\n",
      "15608/50000 [========>.....................] - ETA: 1:11:38 - reward: -64.3368Episode 98: reward: -208.974, steps: 2\n",
      "15609/50000 [========>.....................] - ETA: 1:11:37 - reward: -64.3326Episode 99: reward: -208.974, steps:\n",
      "15833/50000 [========>.....................] - ETA: 1:10:17 - reward: -46.3701\n",
      "episode_reward: -202.45595897435894\n",
      "nb_steps: 2.0\n",
      "14726/50000 [=======>......................] - ETA: 1:22:06 - reward: -41.8549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-03 10:48:25,391]\u001b[0m Trial 8 finished with value: 2.0 and parameters: {'agent': 'CEM', 'windows_length': 1, 'layers': 2, 'n_units_l1': 48, 'n_units_l2': 48, 'activation': 'softmax', 'cem_memory_limit': 601000, 'batch_size': 32}. Best is trial 8 with value: 2.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2890/50000 [>.............................] - ETA: 52:37 - reward: -49.2284Model: \"sequential_1\">.....................] - ETA: 1:\n",
      "_________________________________________________________________\n",
      "16367/50000 [========>.....................] - ETA: 1:08:30 - reward: -48.7310 Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "15647/50000 [========>.....................] - ETA: 1:12:05 - reward: -60.8926 flatten_1 (Flatten)         (None, 41)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 80)                3360      \n",
      "16405/50000 [========>.....................] - ETA: 1:08:48 - reward: -77.0050                                                                 \n",
      "11905/50000 [======>.......................] - ETA: 1:45:12 - reward: -71.5101 dense_4 (Dense)             (None, 240)               19440     \n",
      " 2895/50000 [>.............................] - ETA: 52:36 - reward: -49.1386                                                                 \n",
      " dense_5 (Dense)             (None, 58)                13978     \n",
      "14848/50000 [=======>......................] - ETA: 1:22:11 - reward: -41.8979                                                                 \n",
      "15851/50000 [========>.....................] - ETA: 1:11:25 - reward: -64.3310=================================================================\n",
      "Total params: 36,778\n",
      " 2898/50000 [>.............................] - ETA: 52:34 - reward: -49.0872Trainable params: 36,778\n",
      "16070/50000 [========>.....................] - ETA: 1:10:08 - reward: -46.4441Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "15650/50000 [========>.....................] - ETA: 1:12:05 - reward: -60.9070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/optuna/distributions.py:560: UserWarning: The distribution is specified by [1000, 1000000] and step=50000, but the range is not divisible by `step`. It will be replaced by [1000, 951000].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16065/50000 [========>.....................] - ETA: 1:11:15 - reward: -64.3071Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "16622/50000 [========>.....................] - ETA: 1:08:38 - reward: -77.0093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17705/50000 [=========>....................] - ETA: 35:15 - reward: -49.0286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:103\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(futures) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_jobs:\n\u001b[0;32m--> 103\u001b[0m     completed, futures \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFIRST_COMPLETED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    305\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mload_study(\n\u001b[1;32m      9\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m_study_name,\n\u001b[1;32m     10\u001b[0m         storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmysql://kniffel:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@kniffel-do-user-12010256-0.b.db.ondigitalocean.com:25060/kniffel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis feature will be removed in v4.0.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:108\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[1;32m    106\u001b[0m                         f\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m--> 108\u001b[0m                 futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    109\u001b[0m                     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    110\u001b[0m                         _optimize_sequential,\n\u001b[1;32m    111\u001b[0m                         study,\n\u001b[1;32m    112\u001b[0m                         func,\n\u001b[1;32m    113\u001b[0m                         \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    114\u001b[0m                         timeout,\n\u001b[1;32m    115\u001b[0m                         catch,\n\u001b[1;32m    116\u001b[0m                         callbacks,\n\u001b[1;32m    117\u001b[0m                         gc_after_trial,\n\u001b[1;32m    118\u001b[0m                         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    119\u001b[0m                         time_start,\n\u001b[1;32m    120\u001b[0m                         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m                     )\n\u001b[1;32m    122\u001b[0m                 )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     study\u001b[38;5;241m.\u001b[39m_optimize_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17708/50000 [=========>....................] - ETA: 35:15 - reward: -49.0314"
     ]
    }
   ],
   "source": [
    "if create_new == \"true\":\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"maximize\",\n",
    "        storage=f\"mysql://kniffel:{_pw}@kniffel-do-user-12010256-0.b.db.ondigitalocean.com:25060/kniffel\",\n",
    "    )\n",
    "else:\n",
    "    study = optuna.load_study(\n",
    "        study_name=_study_name,\n",
    "        storage=f\"mysql://kniffel:{_pw}@kniffel-do-user-12010256-0.b.db.ondigitalocean.com:25060/kniffel\",\n",
    "    )\n",
    "\n",
    "study.optimize(\n",
    "    objective_1,\n",
    "    n_trials=250,\n",
    "    catch=(ValueError,),\n",
    "    n_jobs=12,\n",
    "    gc_after_trial=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J-FMgpdHFMog"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "ai-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "19064c4f032cd77faf21ab99fa1118d479a03b2d347142ed5bcca147285dae1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
